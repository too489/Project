package Hw1;
import java.io.IOException;
import java.util.*;
import java.util.Map.Entry;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapred.MapReduceBase;
import org.apache.hadoop.mapred.OutputCollector;
import org.apache.hadoop.mapred.Reporter;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.Mapper;
import org.apache.hadoop.mapreduce.Reducer;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;


public class Result_Reducer extends MapReduceBase implements Reducer<Text,Text, Text, Text>{
		private Text result = new Text();
		public Map<String ,String> map = new HashMap<String, String>();
		public void reduce(Text key,Iterable<Text> values,OutputCollector<Text,LongWritable> output,Reporter reporter)throws IOException, InterruptedException{
			
			map.put(key.toString(),values.toString());
			sortMap(map);
			
		}	
		public void cleanup(Context context) throws IOException, InterruptedException {
				
			sortMap(map,context);
			
		}
		
		public void sortMap (Map<String,Integer> unsortMap ) throws IOException, InterruptedException{
			Map<String, Integer> hashmap = new HashMap<String,Integer>();
			int count = 0;
			List<Map.Entry<String,Integer>> list = new LinkedList<Map.Entry<String,Integer>>(unsortMap.entrySet());
			Collections.sort(list, new Comparator<Map.Entry<String,Integer>>(){
				public int compare (Map.Entry<String,Integer> o1, Map.Entry<String,Integer> o2) {
					return o2.getValue().compareTo(o1.getValue());
				}
			});
			for(Map.Entry<String,Integer> entry : list) {
				if(count>3)
					break;
				Run_test.Most_Loc[count]=entry.getKey();
				context.write(new Text(entry.getKey()), new LongWritable(entry.getValue()));
				hashmap.put(entry.getKey(),entry.getValue());count++;
			}
			
		}
}
